{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6916830b",
   "metadata": {},
   "source": [
    "### Setting environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04023432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the os module to interact with the operating system environment variables\n",
    "import os\n",
    "\n",
    "# Set the LANGCHAIN_TRACING_V2 environment variable to enable tracing for LangChain version 2\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "# Set the LANGCHAIN_PROJECT environment variable to specify the project name in LangChain\n",
    "os.environ['LANGCHAIN_PROJECT'] = \"agentic-workflow\"\n",
    "\n",
    "# Set the LANGSMITH_USER_HANDLE environment variable with your LangSmith user handle\n",
    "os.environ['LANGSMITH_USER_HANDLE'] = \"pallaanji\"\n",
    "\n",
    "# Set the SERPAPI_API_KEY environment variable with your SERP API key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22564650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Client class from the langsmith module to create a client instance\n",
    "from langsmith import Client\n",
    "\n",
    "# Initialize a new client instance using the Client class\n",
    "client = Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92085946",
   "metadata": {},
   "source": [
    "### Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "356fbe19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the itemgetter function from the operator module to extract items from objects\n",
    "from operator import itemgetter\n",
    "\n",
    "# Import the hub module from langchain to access its functionalities\n",
    "from langchain import hub\n",
    "\n",
    "# Import the AgentExecutor class from langchain.agents to execute agent actions\n",
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "# Import the load_tools function from langchain.agents to load necessary tools for agents\n",
    "from langchain.agents import load_tools\n",
    "\n",
    "# Import the format_to_openai_functions function from langchain.agents.format_scratchpad\n",
    "# to convert scratchpad content into OpenAI functions\n",
    "from langchain.agents.format_scratchpad import format_to_openai_functions\n",
    "\n",
    "# Import the OpenAIFunctionsAgentOutputParser class from langchain.agents.output_parsers\n",
    "# to parse the output of agents into OpenAI functions\n",
    "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\n",
    "\n",
    "# Import the ChatOpenAI class from langchain.chat_models to interact with OpenAI chat models\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# Import the format_tool_to_openai_function function from langchain.tools.render\n",
    "# to format tools into OpenAI functions\n",
    "from langchain.tools.render import format_tool_to_openai_function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8232b9e5",
   "metadata": {},
   "source": [
    "### Initializing LLMs and Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea8db6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the ChatOpenAI class to interact with OpenAI's chat models\n",
    "# llm = ChatOpenAI()\n",
    "from langchain_openai import ChatOpenAI,AzureOpenAIEmbeddings,AzureChatOpenAI\n",
    "llm = AzureChatOpenAI(model=\"anji-gpt-35-turbo\", temperature=0,api_version = \"2024-02-01\")\n",
    "\n",
    "# Load tools such as serpapi, wikipedia, and llm-math using the load_tools function\n",
    "tools = load_tools([\"serpapi\", \"wikipedia\", \"llm-math\"], llm=llm)\n",
    "\n",
    "# Bind the loaded tools to the language model (llm) by converting them into OpenAI functions\n",
    "llm_with_tools = llm.bind(functions=[format_tool_to_openai_function(t) for t in tools])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa106d68",
   "metadata": {},
   "source": [
    "### Prompt design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a44fc60b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variables=['agent_scratchpad', 'input'] input_types={'agent_scratchpad': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]} metadata={'lc_hub_owner': 'wfh', 'lc_hub_repo': 'agent-lcel-prompt', 'lc_hub_commit_hash': '08dfba0e76aaf99490887fca749eedca2541c34fcde5a21df5bf8b2960938e01'} messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are helpful AI assistant.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}')), MessagesPlaceholder(variable_name='agent_scratchpad')]\n"
     ]
    }
   ],
   "source": [
    "# Use the hub.pull method from the langchain hub to retrieve a specific prompt\n",
    "prompt = hub.pull(\"wfh/agent-lcel-prompt\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db10f919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function named format_scratchpad that takes a dictionary as input\n",
    "# The dictionary is expected to contain a key \"intermediate_steps\" whose value is processed\n",
    "# using the format_to_openai_functions function to convert intermediate steps into a string\n",
    "def format_scratchpad(x: dict) -> str:\n",
    "    return format_to_openai_functions(x[\"intermediate_steps\"])\n",
    "\n",
    "# Define a function named get_chat_history that takes a list as input\n",
    "# The list is expected to contain a dictionary with a key \"chat_history\"\n",
    "# If the \"chat_history\" key exists, its value is returned; otherwise, an empty list is returned\n",
    "def get_chat_history(x: list) -> str:\n",
    "    return x.get(\"chat_history\", [])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ba6a1d",
   "metadata": {},
   "source": [
    "### Creating agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f3ccd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an agent configuration dictionary with specific functions mapped to keys\n",
    "# \"input\" is mapped to the itemgetter function to extract the \"input\" field from a given object\n",
    "# \"agent_scratchpad\" is mapped to the format_scratchpad function to process intermediate steps\n",
    "# \"chat_history\" is mapped to the get_chat_history function to retrieve chat history\n",
    "agent_config = {\n",
    "    \"input\": itemgetter(\"input\"),\n",
    "    \"agent_scratchpad\": format_scratchpad,\n",
    "    \"chat_history\": get_chat_history\n",
    "}\n",
    "# Apply the agent configuration to a prompt using the pipe operator\n",
    "# This involves pulling the prompt from the hub, binding it with the loaded tools (llm_with_tools),\n",
    "# and then processing it through the agent configuration\n",
    "# The result is then parsed by the OpenAIFunctionsAgentOutputParser to format the output\n",
    "agent = (\n",
    "    agent_config\n",
    "    | prompt\n",
    "    | llm_with_tools\n",
    "    | OpenAIFunctionsAgentOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72efca58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate an AgentExecutor object with the specified agent configuration and tools\n",
    "agent_executor = AgentExecutor(\n",
    "    agent = agent,\n",
    "    tools = tools,\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7146d69",
   "metadata": {},
   "source": [
    "### Questions to agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "18c5b20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [\"who is Indian prime minister\",\n",
    "          \"What is US President's age and return the number age multiplied by two\",\n",
    "          \"what is the name of OpenAI's new AI model?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "625bea3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `wikipedia` with `List of presidents of the United States`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Search` with `OpenAI's new AI model name`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Search` with `Current Indian Prime Minister`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3mGPT-4o\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in StdOutCallbackHandler.on_tool_end callback: ValueError('I/O operation on closed file')\n",
      "Error in StdOutCallbackHandler.on_tool_end callback: ValueError('I/O operation on closed file')\n",
      "Error in StdOutCallbackHandler.on_agent_finish callback: ValueError('I/O operation on closed file')\n",
      "Error in StdOutCallbackHandler.on_chain_end callback: ValueError('I/O operation on closed file')\n",
      "Error in StdOutCallbackHandler.on_agent_finish callback: ValueError('I/O operation on closed file')\n",
      "Error in StdOutCallbackHandler.on_chain_end callback: ValueError('I/O operation on closed file')\n"
     ]
    }
   ],
   "source": [
    "results = agent_executor.batch([{\"input\": x} for x in inputs], return_exceptions=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84da0a0-0a46-4553-a92c-bcc1fad41bc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
