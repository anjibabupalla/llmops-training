{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a RAG pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set the LANGCHAIN_TRACING_V2 environment variable to enable tracing for LangChain version 2\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "\n",
    "# Set the LANGCHAIN_API_KEY environment variable with your LangChain API key\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"\"\n",
    "\n",
    "# Set the OPENAI_API_KEY environment variable with your OpenAI API key\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "\n",
    "# Set the PINECONE_API_KEY environment variable with your Pinecone API key\n",
    "os.environ[\"PINECONE_API_KEY\"] = \"\"\n",
    "\n",
    "# Set the LANGCHAIN_PROJECT environment variable to specify the project name for LangChain\n",
    "os.environ['LANGCHAIN_PROJECT'] = \"earnings-call\"\n",
    "\n",
    "# Set the LANGSMITH_USER_HANDLE environment variable with your Langsmith user handle\n",
    "os.environ['LANGSMITH_USER_HANDLE'] = \"bhaskarjit/earning-call-rag\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the json module for handling JSON data\n",
    "import json\n",
    "\n",
    "# Import StrOutputParser from langchain_core.output_parsers for parsing string outputs\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Import RunnablePassthrough from langchain_core.runnables for running tasks in a passthrough manner\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# Import RunnableParallel from langchain_core.runnables for running tasks in parallel\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "# Import ChatPromptTemplate from langchain_core.prompts for creating chat prompt templates\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Import OpenAIEmbeddings from langchain_openai for working with OpenAI embeddings\n",
    "from langchain_openai import OpenAIEmbeddings \n",
    "\n",
    "# Import ChatOpenAI from langchain_openai for interacting with the OpenAI chat model\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Import PineconeVectorStore from langchain_pinecone for managing vector storage in Pinecone\n",
    "from langchain_pinecone import PineconeVectorStore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining globle variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the index name for storing or retrieving data, in this case, 'earning-calls'\n",
    "INDEX_NAME = 'earning-calls'\n",
    "\n",
    "# Set the number of top results to return, here set to 6\n",
    "TOP_K = 6\n",
    "\n",
    "# Specify the quarter for which the data is relevant, in this example, Q1 (Quarter 1)\n",
    "QUARTER = \"Q1\"\n",
    "\n",
    "# Define the filename of the document being processed, in this case, \"Adani Enterprises Ltd.pdf\"\n",
    "FILENAME = \"Adani Enterprises Ltd.pdf\"\n",
    "\n",
    "# Specify the fiscal year for the data, in this example, FY24 (Fiscal Year 2024)\n",
    "YEAR = \"FY24\"\n",
    "\n",
    "# Initialize OpenAIEmbeddings with the specified model for generating text embeddings\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")\n",
    "\n",
    "# Initialize ChatOpenAI with the specified model and temperature for generating chat responses\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PineconeVectorStore instance with the specified index name and embedding model\n",
    "index = PineconeVectorStore(\n",
    "        index_name = INDEX_NAME,\n",
    "        embedding = embeddings\n",
    "    )\n",
    "\n",
    "# Convert the PineconeVectorStore instance into a retriever object for searching\n",
    "retriver = index.as_retriever(search_kwargs={\"filter\":{\"quarter\": QUARTER, \"filename\": FILENAME},\"k\": TOP_K})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='mining is, all our commercial mining activities, be it India or overseas will fall under the \\ncommercial mining which fall under our natural resource s region of which my colleague Vinay \\nis the CEO . \\nModerator:  Thank you. The  next question is from the line of Gaurav Singhal from Aspex Management \\nLimited . Please go ahead.  \\nGaurav Singhal:  Two questions from me. So, one is, can you help give a break up of the $3.7 billion CAPEX plan \\nfor this year  across the different segment s? Thank you.  \\nRobbie Singh : Approximately about $300 million for Green Hydrogen, $1.1 billi on for airports, approximately \\n$1.7 billion for the road network, just under $100 million  for water , just under $200 million for \\nthe Data Center, and then small completion cost for the copper project just under $200 million.  \\nGaurav Singhal:  And then secondly in terms of financing the CAPEX, the board had passed resolution to al low \\nthe group  to raise about 12,500 crores in equity, in that part of the financing for this CAPEX ?', metadata={'filename': 'Adani Enterprises Ltd.pdf', 'page': 8.0, 'quarter': 'Q1', 'source': 'Data\\\\FY24\\\\Q1\\\\Adani Enterprises Ltd.pdf', 'year': 'FY24'}),\n",
       " Document(page_content='acquire it. And therefore,  total CAPEX as we had indicated even last year , this year was around \\n$3.7 billion across Adani Enterprise and will continue that way.  Another on the utility portfolio , \\nwith the utility portfolio that we have, and transport and logistics portfolio we have and the core \\nasset portfolio we have which is in the primary industry. They are driven by the fundamentals \\nof the users and consumers in India plus the demands in India which  is not changing. So, a report', metadata={'filename': 'Adani Enterprises Ltd.pdf', 'page': 6.0, 'quarter': 'Q1', 'source': 'Data\\\\FY24\\\\Q1\\\\Adani Enterprises Ltd.pdf', 'year': 'FY24'}),\n",
       " Document(page_content='the overall CAPEX for FY24 for the Company  and I mean even we have completed a large \\nM&A in our group Company  cement business,  and this probably is the first large obviously \\nM&A  after the Hindenburg  report . Are you looking for accelerating CAPEX in Adani Enterprise \\nas well which was just said to have sort of mild slow down in past quarter?  \\nRobbie Singh : No, I think that was probably more media than anything else. We had always said around 28th, \\n29th of January . We had said that in the core businesses the CAPEX will continue. There is \\nabsolutely no reason for any of that to ha ppen. That whole frenzy of half -baked articles and \\nstories were related to people’s perception rather than what we had actually said. So, what you \\nare seeing is basically the core CAPEX, be it Adani Green, be it Adani Transmission, be it Adani \\nPorts, be it Adani Total Gas, be it AEL, be it Airports, be it the Green Hydrogen Ecosystem, be', metadata={'filename': 'Adani Enterprises Ltd.pdf', 'page': 6.0, 'quarter': 'Q1', 'source': 'Data\\\\FY24\\\\Q1\\\\Adani Enterprises Ltd.pdf', 'year': 'FY24'}),\n",
       " Document(page_content='are seeing is basically the core CAPEX, be it Adani Green, be it Adani Transmission, be it Adani \\nPorts, be it Adani Total Gas, be it AEL, be it Airports, be it the Green Hydrogen Ecosystem, be \\nit Datacenter, everything is continuing a s normal. So, it was only the perception outside that \\nsomething is going to be a slowdown in the core, that w as never the case. We never said that.  \\nAnd what you are seeing here is naturally when the opportunity came along, it was a key \\nopportunity for our  portfolio Company , Ambuja to acquire a great asset available for which is \\nsynergistic to its portfolio, synergistic from a logistics point of view, massively positive in terms \\nof earnings. They did that. If any asset like this comes available to us in a core portfolio , we will \\nacquire it. And therefore,  total CAPEX as we had indicated even last year , this year was around \\n$3.7 billion across Adani Enterprise and will continue that way.  Another on the utility portfolio ,', metadata={'filename': 'Adani Enterprises Ltd.pdf', 'page': 6.0, 'quarter': 'Q1', 'source': 'Data\\\\FY24\\\\Q1\\\\Adani Enterprises Ltd.pdf', 'year': 'FY24'}),\n",
       " Document(page_content='Adani Enterprises Limited  \\nAugust 03 , 2023 \\n \\n Page 6 of 11 \\nairport side , we will have capex this year just about US $ 1.1 billion , all of this just to clarify we \\nare assuming  Rs.80 to a dollar rate , adjust for that , so about US $1.1 billion this year would be \\nthe CAPEX on airport. It will broadly remain in that range for the next  year then there will be \\ndecline , once we complete the first phase  of our development plan in airports . \\nModerator : Thank you. The next question is from the line of Nikhil Abhyankar from ICICI Securities. Please \\ngo ahead.  \\nNikhil Abhyankar : Congrats on a good set of numbers . What is the guidance for commercial mining this year?  And \\nthe reason for asking the question is  our production has fallen like 10% Y-o-Y, so what is the \\nexact reason for the same?  \\nVinay Prakash : As for your first question  about the commercial mines, we are hopeful of starting the open  cut', metadata={'filename': 'Adani Enterprises Ltd.pdf', 'page': 5.0, 'quarter': 'Q1', 'source': 'Data\\\\FY24\\\\Q1\\\\Adani Enterprises Ltd.pdf', 'year': 'FY24'}),\n",
       " Document(page_content='We would be well on the way to  completing 1 gigaw att before the end of th is decade . \\nAditya Bhartia : And lastly, sir what are our CAPEX plans especially for green hydrogen, airports and data center \\nsegments for the next 3 years?  \\nRobbie Singh : Overall in the longer term , the CAPEX plans don’t alter for the asset like for green hydrogen  \\nfull 3-million -ton facility , approximately $ 50 billion as we have outlined  in previous  year, so \\nthat plan continues forward as it is . Also this year,  we would touch just about between 300 \\nmillion to 400 million and then it rapidly starts rising from next year  and the year after . On the', metadata={'filename': 'Adani Enterprises Ltd.pdf', 'page': 4.0, 'quarter': 'Q1', 'source': 'Data\\\\FY24\\\\Q1\\\\Adani Enterprises Ltd.pdf', 'year': 'FY24'})]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriver.invoke(\"what is the capex?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain import hub\n",
    "# prompt = hub.pull(\"pallaanji/patient-review\")\n",
    "# print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This template is designed for a chatbot that acts as an expert Q&A system\n",
    "chat_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        # Define the system message that outlines the chatbot's role and rules\n",
    "        (\"system\", \"You are financial advisor who response to the certain Quetion and Answers. Limit your response to the infromation from documents\"),\n",
    "        \n",
    "        # Define the human message that provides context information and a query\n",
    "        (\"human\", \"Context information is below.\\n---------------------\\n{context}\\n---------------------\\nGiven the context information and not prior knowledge, answer the query.\\nQuery: {query}\\nAnswer: \"),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: You are financial advisor who response to the certain Quetion and Answers. Limit your response to the infromation from documents\n",
      "Human: Context information is below.\n",
      "---------------------\n",
      "THIS IS A SAMPLE CONTEXT TO SEE HOW THE PROMPT LOOKS\n",
      "---------------------\n",
      "Given the context information and not prior knowledge, answer the query.\n",
      "Query: THIS IS A SAMPLE QUERY?\n",
      "Answer: \n"
     ]
    }
   ],
   "source": [
    "print(chat_template.format(context=\"THIS IS A SAMPLE CONTEXT TO SEE HOW THE PROMPT LOOKS\", query=\"THIS IS A SAMPLE QUERY?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the RAG chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to format documents by joining their page content with newlines\n",
    "def format_docs(docs):\n",
    "    # Join the page content of each document with two newlines between them\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Create a runnable chain for generating responses from formatted documents\n",
    "# This chain starts with formatting the documents, then uses the chat template,\n",
    "# processes the response through the language model, and finally parses the output\n",
    "rag_chain_from_docs = (\n",
    "    RunnablePassthrough.assign(context = (lambda x: format_docs(x['context'])))\n",
    "    |chat_template\n",
    "    |llm\n",
    "    |StrOutputParser()\n",
    ")\n",
    "\n",
    "# Create a runnable chain for retrieving context and generating answers in parallel\n",
    "# This chain retrieves context using the retriever and formats the query,\n",
    "# then generates answers using the previously defined chain for formatted documents\n",
    "rag_chain_with_source = RunnableParallel(\n",
    "    {\"context\": retriver, \"query\": RunnablePassthrough()}\n",
    ").assign(answer = rag_chain_from_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The consolidated total income for the quarter was Rs. 25,810 crores.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain_with_source.invoke(\"What was the income?\")\n",
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Versioning\n",
    "\n",
    "Loading a Specific Version of a Prompt:\n",
    "\n",
    "1. **Version Tracking in Repositories:**\n",
    "   - Each push to a prompt repository saves a new version, identified by a unique commit hash.\n",
    "\n",
    "2. **Loading the Latest Version:**\n",
    "   - By default, accessing the repo will load the most recent version of a given prompt.\n",
    "\n",
    "3. **Loading a Specific Version:**\n",
    "   - To load a specific version, include its commit hash with the prompt name.\n",
    "   - Example: For loading the \"earnings-call-rag\" with version `6214c98a`, append this hash to the prompt name in your loading command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchainhub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "prompt = hub.pull(\"bhaskarjit/earnings-call-rag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "System: You are an expert Q&A system that is trusted around the world.\n",
      "Always answer the query using the provided context information, and not prior knowledge.\n",
      "Some rules to follow:\n",
      "1. Never directly reference the given context in your answer.\n",
      "2. Avoid statements like 'Based on the context, ...' or 'The context information ...' or anything along those lines.\n",
      "Human: Context information is below.\n",
      "---------------------\n",
      "THIS IS A SAMPLE CONTEXT TO SEE HOW THE PROMPT LOOKS\n",
      "---------------------\n",
      "Given the context information and not prior knowledge, answer the query.\n",
      "Use Bullet poits whenever possible in the answer.\n",
      "Query: THIS IS A SAMPLE QUERY?\n",
      "Answer: \n"
     ]
    }
   ],
   "source": [
    "print(prompt.format(context=\"THIS IS A SAMPLE CONTEXT TO SEE HOW THE PROMPT LOOKS\", query=\"THIS IS A SAMPLE QUERY?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain_from_docs = (\n",
    "    RunnablePassthrough.assign(context=(lambda x: format_docs(x[\"context\"])))\n",
    "    | prompt # placing the newly loaded prompt here\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain_with_source = RunnableParallel(\n",
    "    {\"context\": retriver, \"query\": RunnablePassthrough()}\n",
    ").assign(answer=rag_chain_from_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- The consolidated total income was at Rs. 25,810 crores.\n"
     ]
    }
   ],
   "source": [
    "response = rag_chain_with_source.invoke(\"What was the income?\")\n",
    "print(response['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to Share Prompts on LangChain Hub:\n",
    "\n",
    "1. **Getting Started:**\n",
    "   - Getting prompts from LangChain Hub is easy, and so is sharing your own prompts.\n",
    "\n",
    "   - This lets you easily share and manage your own prompts.\n",
    "\n",
    "2. **Making a Prompt:**\n",
    "\n",
    "   - First, create a prompt that fits what you need.\n",
    "\n",
    "   - Make sure it follows the rules of LangChain Hub.\n",
    "\n",
    "3. **Sharing Process:**\n",
    "\n",
    "   - The sharing has two important parts:\n",
    "     - **Account Handle:** Your special name in LangChain Hub, like `me-langchain-user`.\n",
    "     - **Prompt Name:** A clear name for your prompt, showing what it does.\n",
    "\n",
    "4. **How to Share with Code:**\n",
    "   - This is a simple way to share:\n",
    "     ```python\n",
    "     from langchain import hub\n",
    "\n",
    "     # Define your prompt\n",
    "     my_prompt = \"...\"  # Your prompt content goes here\n",
    "\n",
    "     # Share it on LangChain Hub\n",
    "     hub.push(f\"{account_handle}/{prompt_name}\", my_prompt)\n",
    "     ```\n",
    "     - Replace `account_handle` with your username and `my_prompt` with your prompt's name.\n",
    "     \n",
    "     - Make sure `my_prompt` follows LangChain PromptTemplate.\n",
    "\n",
    "5. **Using Your Shared Prompt:**\n",
    "   - Once it's shared, you can use it in different apps through LangChain Hub.\n",
    "   - This makes it easy to share with others, work together, and manage your prompts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,\n",
       " [SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['\\n\"patient_name\"'], template='You are an assistant that supports a healthcare provider in analyzing patient reviews\\nYour goal is to extract key information from the user message, including the patient\\'s\\nname, the doctor mentioned in the review, the review rating, a brief description of the\\nreview, and whether the patient expressed satisfaction with their appointment. Go\\nthrough the user\\'s feedback step by step, and generate a structured output for further\\nanalysis by the healthcare provider in the below format\\n{\\n\"patient_name\": <extract the patient’s first and last name from the corpus>,\\n\"consulting_doctor\": <extract the doctor’s first and last name and credentials from\\nthe\\ncorpus>,\\n\"review_rating\": <this has to be a number out of 5 points - if you cannot find a\\nrating, output NULL>,\\n\"review_description\": <summarize the review at most in 50 words>\\n\"satisfaction\": <this has to be a TRUE or FALSE value - arrive at this conclusion using\\nyour own judgment>,\\n“issue_tags”: <in the case of a negative review or dissatisfaction, add tags which\\nspecify the area of dissatisfaction>\\n}')),\n",
       "  HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], template='{question}'))])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(prompt.messages), prompt.messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], template='{question}'))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.messages[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['question'], template='{question}')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.messages[1].prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(prompt.messages[1].prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt.messages[1].prompt.template = 'Context information is below.\\n---------------------\\n{context}\\n---------------------\\nGiven the context information and not prior knowledge, answer the query.\\nUse Bullet poits whenever possible in the answer.\\nQuery: {query}\\nAnswer: '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context information is below.\n",
      "---------------------\n",
      "{context}\n",
      "---------------------\n",
      "Given the context information and not prior knowledge, answer the query.\n",
      "Use Bullet poits whenever possible in the answer.\n",
      "Query: {query}\n",
      "Answer: \n"
     ]
    }
   ],
   "source": [
    "print(prompt.messages[1].prompt.template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Added the following line in the prompt: `Use Bullet poits whenever possible in the answer.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "handle = \"pallaanji\"\n",
    "prompt_url = hub.push(f\"{handle}/earnings-call-rag\", prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://smith.langchain.com/hub/pallaanji/earnings-call-rag/532d741a'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://smith.langchain.com/hub/pallaanji/patient-review/81ce0445'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import hub\n",
    "prompt = hub.pull(\"bhaskarjit/patient-review\")\n",
    "hub.push(\"pallaanji/patient-review\", prompt)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
